{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MIT License\n",
    "\n",
    "# Copyright (c) [2019] [Jayden Booth]\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras import backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 16 \t n: 1\n"
     ]
    }
   ],
   "source": [
    "# Set the defining parameters\n",
    "# n = n_channel complex numbers (so 2n real numbers)\n",
    "# k = log2(M), where M is the number of messages to encode\n",
    "# EbNo is the energy per bit to noise power density\n",
    "\n",
    "# Encoder Parameters\n",
    "M = 16\n",
    "k = np.log2(M)\n",
    "n_channel = 1\n",
    "R = k/n_channel\n",
    "print('M:',M,'\\t','n:',n_channel)\n",
    "\n",
    "# Channel Parameters\n",
    "EbNo=10.0**(7/10.0)\n",
    "noise_std = np.sqrt(1/(2*R*EbNo))\n",
    "num_taps = 3\n",
    "reyleigh_std = num_taps/np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating data of size N\n",
    "N = 16000\n",
    "label = np.random.randint(M,size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating one hot encoded vectors\n",
    "data = []\n",
    "for i in label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 16)\n"
     ]
    }
   ],
   "source": [
    "# checking data shape\n",
    "data = np.array(data)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "13 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "12 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "15 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "12 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# checking generated data with it's label\n",
    "temp_check = [17,23,45,67,89,96,72,250,350]\n",
    "for i in temp_check:\n",
    "    print(label[i],data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that define the Channel. \n",
    "\n",
    "# First the encoder output must be converted to complex samples \n",
    "# Right now I am assuming n = 1 for simplicity\n",
    "\n",
    "def real_to_complex(x):\n",
    "    real = x[:,0]\n",
    "    imag = x[:,1]\n",
    "    return tf.reshape(tf.dtypes.complex(real,imag),shape=[-1,1])\n",
    "\n",
    "def complex_to_real(x):\n",
    "    real = tf.math.real(x)\n",
    "    imag = tf.math.imag(tf.dtypes.cast(x,tf.complex64))\n",
    "    real_expand = tf.expand_dims(real,-1)\n",
    "    imag_expand = tf.expand_dims(imag,-1)\n",
    "    concated = tf.concat([real_expand, imag_expand],-1)\n",
    "    return tf.reshape(concated,shape=[-1,2])\n",
    "\n",
    "# Define the Channel Layer for training, as well as the channel function for testing.\n",
    "# A single tap channel will be implemented initially, and then a multi tap channel will be used.\n",
    "\n",
    "def reyleigh_single_tap_train (x):\n",
    "    EbNo_train = K.variable(5.01187, dtype='float32')  #  coverted 7 db of EbNo\n",
    "    noise_std = K.sqrt(1/(2*R*EbNo_train))\n",
    "    \n",
    "    # Create random Complex Channel with single tap\n",
    "    h_real = 1/np.sqrt(2)*K.random_normal((n_channel,),mean=0,stddev=1)\n",
    "    h_imag = 1/np.sqrt(2)*K.random_normal((n_channel,),mean=0,stddev=1)\n",
    "    h = tf.dtypes.complex(h_real,h_imag)\n",
    "    \n",
    "    # Create random Complex Gaussian Noise\n",
    "    noise_real = 1/np.sqrt(2)*K.random_normal((n_channel,),mean=0,stddev=noise_std)\n",
    "    noise_imag = 1/np.sqrt(2)*K.random_normal((n_channel,),mean=0,stddev=noise_std)\n",
    "    noise = tf.dtypes.complex(noise_real,noise_imag)\n",
    "    \n",
    "    return h*tf.dtypes.cast(x,tf.complex64)+noise\n",
    "\n",
    "def reyleigh_single_tap (signal,noise_std,nrow,ncol):\n",
    "    # Create random Complex Channel with single tap\n",
    "    channel_real = 1/np.sqrt(2)*np.random.randn(nrow,ncol)\n",
    "    channel_imag = 1/np.sqrt(2)*np.random.randn(nrow,ncol)\n",
    "    channel = channel_real + 1j*channel_imag\n",
    "    \n",
    "    # Create random Complex Gaussian Noise\n",
    "    noise_real = noise_std/np.sqrt(2)*np.random.randn(nrow,ncol)\n",
    "    noise_imag = noise_std/np.sqrt(2)*np.random.randn(nrow,ncol)\n",
    "    noise = noise_real + 1j*noise_imag\n",
    "    return np.multiply(channel,signal)+noise\n",
    "\n",
    "def reyleigh_channel(signal,noise_std,nrow,ncol,ntaps):\n",
    "    output = np.zeros([nrow,ncol])\n",
    "    \n",
    "    for L in range(1,ntaps+1):\n",
    "        channel_std = 1/(L*np.sqrt(2))\n",
    "        channel = np.multiply(channel_std,np.random.randn(nrow,ncol))\n",
    "        output = output + np.multiply(signal,channel)\n",
    "\n",
    "    return output + noise_std*np.random.randn(nrow,ncol)\n",
    "\n",
    "def reyleigh_train_2(x):\n",
    "    ntaps = 3\n",
    "    noise_std = 5.01187 #  coverted 7 db of EbNo\n",
    "    nrow = 1\n",
    "    ncol = 2*n_channel\n",
    "    channel_std = 1/(ntaps)\n",
    "    output = x*K.random_normal((2*n_channel,),mean=0,stddev=channel_std)\n",
    "    \n",
    "    for L in range(2,ntaps+1):\n",
    "        channel = K.random_normal((2*n_channel,),mean=0,stddev=channel_std)\n",
    "        output = output + x*channel\n",
    "\n",
    "    return output + K.random_normal((2*n_channel,),mean=0,stddev=noise_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 09:45:14.999471 139959221888832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0719 09:45:15.000325 139959221888832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0719 09:45:15.002620 139959221888832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0719 09:45:15.051457 139959221888832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0719 09:45:15.205537 139959221888832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0719 09:45:15.211582 139959221888832 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defined Autoencoder\n",
    "\n",
    "# Transmitter Layers\n",
    "input_signal = Input(shape=(M,))\n",
    "encoded = Dense(M, activation='relu')(input_signal)\n",
    "encoded1 = Dense(2*n_channel, activation='linear')(encoded)\n",
    "encoded2 = Lambda(lambda x: np.sqrt(2*n_channel)*K.l2_normalize(x,axis=1))(encoded1)\n",
    "\n",
    "# Reyleigh Channel Layer\n",
    "EbNo_train = 5.01187 #  coverted 7 db of EbNo\n",
    "channel_in = Lambda(real_to_complex)(encoded2)\n",
    "channel = Lambda(reyleigh_single_tap_train)(channel_in)\n",
    "channel_out = Lambda(complex_to_real)(channel)\n",
    "\n",
    "# Estimator Layer\n",
    "estimate = Dense(2*num_taps,activation='tanh')(channel_out)\n",
    "estimate1 = Dense(2*num_taps,activation='tanh')(estimate)\n",
    "estimate2 = Dense(2*num_taps,activation='linear')(estimate1)\n",
    "\n",
    "# Transformation Layer\n",
    "merge = keras.layers.concatenate([channel_out,estimate2])\n",
    "transform = Dense(256,activation='relu')(merge)\n",
    "transform = Dense(256,activation='relu')(transform)\n",
    "transform = Dense(256,activation='relu')(transform)\n",
    "transform = Dense(2*n_channel,activation='linear')(transform)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(M, activation='relu')(transform)\n",
    "decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "autoencoder = Model(input_signal, decoded1)\n",
    "adam = Adam(lr=0.01)\n",
    "autoencoder.compile(optimizer=adam, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           272         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            34          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2)            0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            18          lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6)            42          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 6)            42          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8)            0           lambda_4[0][0]                   \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          2304        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          65792       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          65792       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          65792       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           4112        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           272         dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 204,472\n",
      "Trainable params: 204,472\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing summary of layers and it's trainable parameters \n",
    "print (autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 09:45:15.342170 139959221888832 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 2.7768\n",
      "Epoch 2/32\n",
      "16000/16000 [==============================] - 3s 186us/step - loss: 2.7740\n",
      "Epoch 3/32\n",
      "16000/16000 [==============================] - 2s 146us/step - loss: 2.7740\n",
      "Epoch 4/32\n",
      "16000/16000 [==============================] - 2s 133us/step - loss: 2.7744\n",
      "Epoch 5/32\n",
      "16000/16000 [==============================] - 3s 162us/step - loss: 2.7741\n",
      "Epoch 6/32\n",
      "16000/16000 [==============================] - 3s 169us/step - loss: 2.7742\n",
      "Epoch 7/32\n",
      "16000/16000 [==============================] - 3s 180us/step - loss: 2.7743\n",
      "Epoch 8/32\n",
      "16000/16000 [==============================] - 2s 149us/step - loss: 2.7741\n",
      "Epoch 9/32\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 2.7740\n",
      "Epoch 10/32\n",
      "16000/16000 [==============================] - 2s 138us/step - loss: 2.7739\n",
      "Epoch 11/32\n",
      "16000/16000 [==============================] - 3s 160us/step - loss: 2.7737\n",
      "Epoch 12/32\n",
      "16000/16000 [==============================] - 2s 144us/step - loss: 2.7740\n",
      "Epoch 13/32\n",
      "16000/16000 [==============================] - 2s 151us/step - loss: 2.7739\n",
      "Epoch 14/32\n",
      "16000/16000 [==============================] - 3s 166us/step - loss: 2.7741\n",
      "Epoch 15/32\n",
      "16000/16000 [==============================] - 3s 160us/step - loss: 2.7743\n",
      "Epoch 16/32\n",
      "16000/16000 [==============================] - 2s 136us/step - loss: 2.7743\n",
      "Epoch 17/32\n",
      "16000/16000 [==============================] - 2s 135us/step - loss: 2.7741\n",
      "Epoch 18/32\n",
      "16000/16000 [==============================] - 3s 167us/step - loss: 2.7741\n",
      "Epoch 19/32\n",
      "16000/16000 [==============================] - 2s 154us/step - loss: 2.7739\n",
      "Epoch 20/32\n",
      "16000/16000 [==============================] - 3s 178us/step - loss: 2.7742\n",
      "Epoch 21/32\n",
      "16000/16000 [==============================] - 3s 194us/step - loss: 2.7743\n",
      "Epoch 22/32\n",
      "16000/16000 [==============================] - 3s 162us/step - loss: 2.7741\n",
      "Epoch 23/32\n",
      "16000/16000 [==============================] - 2s 133us/step - loss: 2.7741\n",
      "Epoch 24/32\n",
      "16000/16000 [==============================] - 2s 139us/step - loss: 2.7742\n",
      "Epoch 25/32\n",
      "16000/16000 [==============================] - 2s 148us/step - loss: 2.7739\n",
      "Epoch 26/32\n",
      "16000/16000 [==============================] - 2s 129us/step - loss: 2.7742\n",
      "Epoch 27/32\n",
      "16000/16000 [==============================] - 2s 149us/step - loss: 2.7741\n",
      "Epoch 28/32\n",
      "16000/16000 [==============================] - 2s 127us/step - loss: 2.7743\n",
      "Epoch 29/32\n",
      "16000/16000 [==============================] - 2s 144us/step - loss: 2.7748\n",
      "Epoch 30/32\n",
      "16000/16000 [==============================] - 3s 183us/step - loss: 2.7740\n",
      "Epoch 31/32\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 2.7742\n",
      "Epoch 32/32\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 2.7743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a40b8e630>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# traning auto encoder\n",
    "autoencoder.fit(data, data,\n",
    "                epochs=50,\n",
    "                batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making encoder from full autoencoder\n",
    "encoder = Model(input_signal, encoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer dense_10: expected axis -1 of input shape to have value 256 but got shape (None, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2860e25f4923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdeco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdeco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    350\u001b[0m                                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' of input shape to have '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                                 \u001b[0;34m'value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                                 ' but got shape ' + str(x_shape))\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer dense_10: expected axis -1 of input shape to have value 256 but got shape (None, 2)"
     ]
    }
   ],
   "source": [
    "# making decoder from full autoencoder\n",
    "encoded_input = Input(shape=(2*n_channel,))\n",
    "\n",
    "deco = autoencoder.layers[-2](encoded_input)\n",
    "deco = autoencoder.layers[-1](deco)\n",
    "decoder = Model(encoded_input, deco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating data for checking BER\n",
    "# if you're not using t-sne for visulation than set N to 70,000 for better result \n",
    "# for t-sne use less N like N = 1500\n",
    "N = 70000\n",
    "test_label = np.random.randint(M,size=N)\n",
    "test_data = []\n",
    "\n",
    "for i in test_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    test_data.append(temp)\n",
    "    \n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking generated data\n",
    "temp_test = 6\n",
    "print (test_data[temp_test][test_label[temp_test]],test_label[temp_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting learned consteallation diagram\n",
    "\n",
    "scatter_plot = []\n",
    "for i in range(0,M):\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    scatter_plot.append(encoder.predict(np.expand_dims(temp,axis=0)))\n",
    "scatter_plot = np.array(scatter_plot)\n",
    "print (scatter_plot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting constellation diagram\n",
    "import matplotlib.pyplot as plt\n",
    "scatter_plot = scatter_plot.reshape(M,2,1)\n",
    "plt.scatter(scatter_plot[:,0],scatter_plot[:,1])\n",
    "plt.axis((-2.5,2.5,-2.5,2.5))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating BER\n",
    "# this is optimized BER function so it can handle large number of N\n",
    "# previous code has another for loop which was making it slow\n",
    "EbNodB_range = list(np.arange(-4,8.5,0.5))\n",
    "ber = [None]*len(EbNodB_range)\n",
    "for n in range(0,len(EbNodB_range)):\n",
    "    EbNo=10.0**(EbNodB_range[n]/10.0)\n",
    "    noise_std = np.sqrt(1/(2*R*EbNo))\n",
    "    noise_mean = 0\n",
    "    no_errors = 0\n",
    "    nn = N\n",
    "    noise = noise_std * np.random.randn(nn,n_channel)\n",
    "    encoded_signal = encoder.predict(test_data) \n",
    "    final_signal = reyleigh_channel(encoded_signal,noise_std,nn,2*n_channel,1)\n",
    "    pred_final_signal =  decoder.predict(final_signal)\n",
    "    pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "    no_errors = (pred_output != test_label)\n",
    "    no_errors =  no_errors.astype(int).sum()\n",
    "    ber[n] = no_errors / nn \n",
    "    print ('SNR:',EbNodB_range[n],'BER:',ber[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting ber curve\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "plt.plot(EbNodB_range, ber, 'bo',label='Autoencoder(2,2)')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right',ncol = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
